{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b91e64bb",
   "metadata": {},
   "source": [
    "# NextAI Training Pipeline\n",
    "\n",
    "This notebook trains NextAI model using GPT-2 Medium on educational and career guidance data.\n",
    "\n",
    "## Setup Instructions\n",
    "\n",
    "1. Set Runtime to GPU (T4 or better)\n",
    "2. Run all cells in sequence\n",
    "3. Estimated time: 8-12 hours\n",
    "\n",
    "## Hardware Requirements\n",
    "\n",
    "- GPU: T4 (free), V100 (Colab Pro recommended)\n",
    "- RAM: 12GB+\n",
    "- Disk: 20GB+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9a978d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da689d41",
   "metadata": {},
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb2dea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q torch transformers datasets accelerate sentencepiece wandb pyyaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac66374b",
   "metadata": {},
   "source": [
    "## Clone Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d345cfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/SanyamSuyal/NextAI.git\n",
    "%cd NextAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5b39fb",
   "metadata": {},
   "source": [
    "## Mount Google Drive (Optional)\n",
    "\n",
    "Mount your Google Drive to save checkpoints and final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272faff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bb2e11",
   "metadata": {},
   "source": [
    "## Upload Training Data\n",
    "\n",
    "Upload your preprocessed training data (train.txt, val.txt) to the data/processed/ directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f9fb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "os.makedirs('data/processed', exist_ok=True)\n",
    "\n",
    "print(\"Upload train.txt:\")\n",
    "uploaded = files.upload()\n",
    "for filename in uploaded.keys():\n",
    "    os.rename(filename, 'data/processed/train.txt')\n",
    "\n",
    "print(\"\\nUpload val.txt:\")\n",
    "uploaded = files.upload()\n",
    "for filename in uploaded.keys():\n",
    "    os.rename(filename, 'data/processed/val.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426a5cf9",
   "metadata": {},
   "source": [
    "## Verify Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2a6166",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python data/validate_dataset.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788ad93a",
   "metadata": {},
   "source": [
    "## Configure Weights & Biases (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada3d6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f1bf30",
   "metadata": {},
   "source": [
    "## Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a335981e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "config = {\n",
    "    'model_name': 'gpt2-medium',\n",
    "    'output_dir': '/content/drive/MyDrive/NextAI/models',\n",
    "    'training': {\n",
    "        'num_epochs': 3,\n",
    "        'batch_size': 4,\n",
    "        'gradient_accumulation_steps': 8,\n",
    "        'learning_rate': 5e-5,\n",
    "        'warmup_steps': 500,\n",
    "        'weight_decay': 0.01,\n",
    "        'max_grad_norm': 1.0,\n",
    "        'save_steps': 1000,\n",
    "        'eval_steps': 500,\n",
    "        'logging_steps': 100,\n",
    "        'save_total_limit': 3\n",
    "    },\n",
    "    'data': {\n",
    "        'train_file': 'data/processed/train.txt',\n",
    "        'val_file': 'data/processed/val.txt',\n",
    "        'max_length': 512,\n",
    "        'block_size': 512\n",
    "    },\n",
    "    'optimization': {\n",
    "        'optimizer': 'adamw',\n",
    "        'scheduler': 'cosine',\n",
    "        'fp16': True,\n",
    "        'gradient_checkpointing': True\n",
    "    },\n",
    "    'wandb': {\n",
    "        'project': 'nextai',\n",
    "        'entity': 'nextbench',\n",
    "        'log_model': True\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('training/config.yaml', 'w') as f:\n",
    "    yaml.dump(config, f)\n",
    "\n",
    "print(\"Configuration saved!\")\n",
    "print(yaml.dump(config, default_flow_style=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccde0ac",
   "metadata": {},
   "source": [
    "## Start Training\n",
    "\n",
    "This will take 8-12 hours depending on your GPU and dataset size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6078603",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python training/train.py --config training/config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285b94e7",
   "metadata": {},
   "source": [
    "## Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7992451b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch\n",
    "\n",
    "model_path = config['output_dir']\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_path)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_path)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "def generate_response(prompt, max_length=200):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_length=max_length,\n",
    "        temperature=0.7,\n",
    "        top_k=50,\n",
    "        top_p=0.9,\n",
    "        repetition_penalty=1.2,\n",
    "        do_sample=True,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    \n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return response\n",
    "\n",
    "test_prompts = [\n",
    "    \"How can I prepare for JEE Advanced?\",\n",
    "    \"What is the best strategy for getting into IIT Bombay?\",\n",
    "    \"I'm feeling stressed about exams. What should I do?\",\n",
    "    \"Create a roadmap for becoming a data scientist.\"\n",
    "]\n",
    "\n",
    "print(\"Testing NextAI Model:\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for prompt in test_prompts:\n",
    "    print(f\"\\nPrompt: {prompt}\")\n",
    "    print(f\"Response: {generate_response(prompt)}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ca563e",
   "metadata": {},
   "source": [
    "## Download Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571faa35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "shutil.make_archive('nextai_model', 'zip', config['output_dir'])\n",
    "\n",
    "from google.colab import files\n",
    "files.download('nextai_model.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac49bc7",
   "metadata": {},
   "source": [
    "## Push to Hugging Face Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b88aa1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi, login\n",
    "\n",
    "login()\n",
    "\n",
    "api = HfApi()\n",
    "\n",
    "model.push_to_hub(\"SanyamSuyal/NextAI\")\n",
    "tokenizer.push_to_hub(\"SanyamSuyal/NextAI\")\n",
    "\n",
    "print(\"Model pushed to Hugging Face Hub!\")\n",
    "print(\"https://huggingface.co/SanyamSuyal/NextAI\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
